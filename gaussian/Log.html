<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<title></title>
</head>
<body>

<h1>gpr: Log</h1>

<h3>6-17-04</h3>

Massive reorganization from 6-16-04.
<p>
<code>GPR::</code>
Implemented ability to skip initialization of Gaussian data structures 
(for empirical regression with very many data points).
Replaced <code>void expansionDialog(...)</code> with <code>GPR& setUP(void).</code>
<br>
Added constructor takes known function<code> f</code> generating the data instead of data array <code>y</code>.
For experimentation. Streamlines the <code>GPR:: setUP()</code> procedure.
<p>
<code>RegressionPlots::</code> new class, takes over plotting.
<p>
<code>Programs.h</code>: new file, contains the free standing programs.


<h3>6-18-04</h3>

Fixed up <code>RegressionPlots::regressionPlots()</code>. Now works, allocates directories and copies files
correctly. Many new get/set functions in <code>GPR</code>. Objects can now be fully reconfigured after construction.


<h3>6-24-04</h3>

<code>GPR:</code>
We now add <code>DELTA*I</code> to the kernel matrix to ensure positive definiteness
(DELTA=0.01). Condition number of $R$ is reported, DELTA can be increased to improve the
condition number.
<p>
Leave one out cross validation implemented, still bug ridden. 
<p>
Fix up <code>Plot::addFunction, addPoints</code> so as to include a legend.
Hand in name as string parameter.


<h3>6-25-04</h3>

New cross validation <code>GPR::polluteAndPredictCV()</code> implemented. Data are polluted with independent Gaussian noise
of standard deviation sigma and the regressors computed. We then choose the regressor which best predicts the original data.
No recomputation of the Cholesky root necessary, only the coefficients have to be recomputed.

The standard deviation sigma of the pollution should be at least as large as the standard deviation of the original noise in the data.
In the case of exact data reduce the bias against higher order expansions (the factor which enforces exponential dropoff of the errors).

This works better than leave one out cross validation and leaves the complexity at O(n^3).


<h3>6-26-04</h3>

Several new methods for the class <code>PSPlot</code>. <br>
<code>BasisFunctions:</code> Each basis now computes its own roughness penalty factors to be used in
cross  validation .
<p>
<a name="todo-6-26"></a>
<b>To do:</b><br>
Class <code>GPR:</code> add a field <code>sigma</code> for the true standard deviation of the
noise. We need this for cross validation. The noise added in <code>GPR::polluteAndPredictCV()</code>
works best if the noise used for pollution of the data has the same or slightly higher standard deviation
than the noise in the data. Adjust the constructors accordingly. Reduce the roughness penalty in
<code>GPR::polluteAndPredictCV()</code> in case of exact data.
<p>
<code>GPR::polluteAndPredictCV()</code> is also not optimized yet as the kernel matrix and
its Cholesky root are needlessly recomputed. Introduce new 3 fields in <code>GPR</code> for the data and
coefficient vectors after artificial data pollution. Hand these as parameters to the coefficient routines
<code>GPR::EC(),EA()</code>. Then it is unnecessary to allocate a new <code>GPR</code> object for
<code>GPR::polluteAndPredictCV()</code> cross validation.
<p>
Do some experiments with relative noise instead of absolute noise in the data.

</body>
</html>