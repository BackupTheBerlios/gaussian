<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
<title></title>
</head>
<body>

<h1>gpr: Log</h1>

<h3>6-17-04</h3>

Massive reorganization from 6-16-04.
<p>
<code>GPR::</code>
Implemented ability to skip initialization of Gaussian data structures 
(for empirical regression with very many data points).
Replaced <code>void expansionDialog(...)</code> with <code>GPR& setUP(void).</code>
<br>
Added constructor takes known function<code> f</code> generating the data instead of data array <code>y</code>.
For experimentation. Streamlines the <code>GPR:: setUP()</code> procedure.
<p>
<code>RegressionPlots::</code> new class, takes over plotting.
<p>
<code>Programs.h</code>: new file, contains the free standing programs.


<h3>6-18-04</h3>

Fixed up <code>RegressionPlots::regressionPlots()</code>. Now works, allocates directories and copies files
correctly. Many new get/set functions in <code>GPR</code>. Objects can now be fully reconfigured after construction.


<h3>6-24-04</h3>

<code>GPR:</code>
We now add <code>DELTA*I</code> to the kernel matrix to ensure positive definiteness
(DELTA=0.01). Condition number of $R$ is reported, DELTA can be increased to improve the
condition number.
<p>
Leave one out cross validation implemented, still bug ridden. 
<p>
Fix up <code>Plot::addFunction, addPoints</code> so as to include a legend.
Hand in name as string parameter.


<h3>6-25-04</h3>

New cross validation <code>GPR::polluteAndPredictCV()</code> implemented. Data are polluted with independent Gaussian noise
of standard deviation sigma and the regressors computed. We then choose the regressor which best predicts the original data.
No recomputation of the Cholesky root necessary, only the coefficients have to be recomputed.

The standard deviation sigma of the pollution should be at least as large as the standard deviation of the original noise in the data.
In the case of exact data reduce the bias against higher order expansions (the factor which enforces exponential dropoff of the errors).

This works better than leave one out cross validation and leaves the complexity at O(n^3).


<h3>6-26-04</h3>

Several new methods for the class <code>PSPlot</code>. <br>
<code>BasisFunctions:</code> Each basis now computes its own roughness penalty factors to be used in
cross  validation .
<p>
<a name="todo-6-26"></a>
<b>To do:</b><br>
Class <code>GPR:</code> add a field <code>sigma</code> for the true standard deviation of the
noise. We need this for cross validation. The noise added in <code>GPR::polluteAndPredictCV()</code>
works best if the noise used for pollution of the data has the same or slightly higher standard deviation
than the noise in the data. Adjust the constructors accordingly. Reduce the roughness penalty in
<code>GPR::polluteAndPredictCV()</code> in case of exact data.
<p>
<code>GPR::polluteAndPredictCV()</code> is also not optimized yet as the kernel matrix and
its Cholesky root are needlessly recomputed. Introduce new 3 fields in <code>GPR</code> for the data and
coefficient vectors after artificial data pollution. Hand these as parameters to the coefficient routines
<code>GPR::EC(),EA()</code>. Then it is unnecessary to allocate a new <code>GPR</code> object for
<code>GPR::polluteAndPredictCV()</code> cross validation.
<p>
Do some experiments with relative noise instead of absolute noise in the data.



<h3>6-30-04</h3>

<code>GPR::polluteAndPredictCV()</code> optimized.
All necessary data structures added to class (polluted data and coefficient arrays).
Now the basis matrix and Cholesky root are no longer recomputed.<br>
Roughness penalty for exact data eliminated.<br>
Noisy data: still needs experimentation: should we average the error over the added noise? 
Should the added noise have larger standard deviation than the inherent noise in the data?
Is the roughness penalty in the various bases too high?
Note the poor performance on f3 in the Fourier basis.


<h3>7-8-04</h3>

Addition of methods <code>GPR::estimateFunctional </code>and <code>GPR::estimateLinearFunctional </code>
for functional estimation. New files "Functionals.h,cpp", <code>BasisFunctions</code> aquire ability to compute their integrals over
[-1,+1]. Intended purpose: testing Bayesian Monte Carlo.
<p>
Modifications have not yet been compiled. The <code>integrals</code> in <code>BasisFunctions</code>
are not yet implemented. Next: implement these, then write some code to test Bayesian Monte Carlo both with the integrals as linear 
functionals and general functionals.
<p>
<b>Bayesian Monte Carlo.</b> Note: if the basis functions psi_k are orthogonal in L^2(F,dt) and psi_0 is constant then all the integrals
<code>Integral_F psi_k(t)dt,</code> with  k&gt 0, will be zero.
In this case the coefficient of psi_0 is the estimate for the integral. This is the case for both the Fourier basis
and the Legendre basis. In the implementation of the methods for functional estimation almost all terms of the relevant sums are zero.
This precludes meaningful testing. Better: implement evaluation functionals and test the functional estimation methods on these.



</body>
</html>